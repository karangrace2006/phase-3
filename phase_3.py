# -*- coding: utf-8 -*-
"""phase 3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cD3Pyuu4v_Ezzbu58LBvmu7TcrBV94vD
"""

pip install pandas numpy matplotlib scikit-learn tensorflow yfinance

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import yfinance as yf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

# Fetch historical stock data
ticker = 'TSLA'  # Tesla stock as an example
data = yf.download(ticker, start='2015-01-01', end='2025-01-01')

# Display the first few rows of the dataset
print(data.head())

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import yfinance as yf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

# Fetch historical stock data
ticker = 'TSLA'  # Tesla stock as an example
data = yf.download(ticker, start='2015-01-01', end='2025-01-01')

# Using the 'Close' column for prediction
close_prices = data['Close'].values.reshape(-1, 1)

# Scale the data to a range between 0 and 1 for better performance of LSTM
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(close_prices)

# Create a function to prepare the dataset for LSTM (sliding window)
def create_dataset(data, time_step=60):
    X, y = [], []
    for i in range(len(data) - time_step - 1):
        X.append(data[i:(i + time_step), 0])
        y.append(data[i + time_step, 0])
    return np.array(X), np.array(y)

# Prepare the data
time_step = 60  # Using past 60 days to predict the next day
X, y = create_dataset(scaled_data, time_step)

# Reshape X to be compatible with LSTM input: [samples, time steps, features]
X = X.reshape(X.shape[0], X.shape[1], 1)

# Manual splitting into training and testing datasets (80% train, 20% test)
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Now, X_train, X_test, y_train, and y_test are properly split for time series forecasting.

# Build LSTM Model
model = Sequential()

# Adding LSTM layer
model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))
model.add(Dropout(0.2))  # Dropout to prevent overfitting

model.add(LSTM(units=50, return_sequences=False))
model.add(Dropout(0.2))

model.add(Dense(units=1))  # Output layer with 1 unit for prediction

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))

# Make predictions
predictions = model.predict(X_test)

# Inverse transform the predictions and actual values to get original values
predicted_stock_price = scaler.inverse_transform(predictions)
actual_stock_price = scaler.inverse_transform(y_test.reshape(-1, 1))

# Plot the results
plt.figure(figsize=(10, 6))
plt.plot(actual_stock_price, color='red', label=f'Actual {ticker} Stock Price')
plt.plot(predicted_stock_price, color='blue', label=f'Predicted {ticker} Stock Price')
plt.title(f'{ticker} Stock Price Prediction')
plt.xlabel('Time')
plt.ylabel('Stock Price')
plt.legend()
plt.show()

from sklearn.metrics import mean_squared_error
import math

# Calculate RMSE
rmse = math.sqrt(mean_squared_error(actual_stock_price, predicted_stock_price))
print(f'Root Mean Squared Error: {rmse}')